[[java-hashmap8]]
= HashMap

[[java-hashmap8-overview]]
== 概述

`HashMap` 是基于哈希表的 `Map` 接口的非同步实现.此实现提供所有可选的映射操作, 并允许使用 `null` 值和 `null` 键.此类不保证映射的顺序,特别是它不保证该顺序恒久不变.

[[java-hashmap8-data]]
== HashMap 的数据结构

在 Java 编程语言中,最基本的结构就是两种,一个是数组,另外一个是模拟指针(引用),所有的数据结构都可以用这两个基本结构来构造的,`HashMap` 也不例外.

`HashMap` 实际上是一个 "链表散列" 的数据结构,即数组和链表的结合体.

image::{oss-images}/collection/java-hashmap1.png[]

从上图中可以看出,`HashMap` 底层就是一个数组结构,类型为 `Node<K,V>[] table`,数组中的每一项又是一个链表，有 `next` 指针指向下一个对象组成链表。

我们来看看 `HashMap` 的节点源码 Java 代码:

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
/**
 * The table, initialized on first use, and resized as
 * necessary. When allocated, length is always a power of two.
 * (We also tolerate length zero in some operations to allow
 * bootstrapping mechanics that are currently not needed.)
 */
transient Node<K,V>[] table;

static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;
        // 省略其他方法...
 }

 // 红黑树
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;  // red-black tree links
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;    // needed to unlink next upon deletion
    boolean red;
   // 省略其他方法...
}
----

[[java-hashmap8-init]]
== 初始化

HashMap 提供了四个初始化方法

*  HashMap(): 构建一个初始容量为 `16`,负载因子为 `0.75` 的 HashMap.
*  HashMap(int initialCapacity): 构建一个初始容量为 `initialCapacity`,负载因子为 `0.75` 的 `HashMap`.
*  HashMap(int initialCapacity, float loadFactor): 以指定初始容量、指定的负载因子创建一个 `HashMap`.
* HashMap(Map<? extends K, ? extends V> m): 构造一个与指定 `Map` 具有相同映射的新的 `HashMap`。

我们可以来看看他们的源码：

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
static final int MAXIMUM_CAPACITY = 1 << 30;

public HashMap(int initialCapacity, float loadFactor) {
    // 如果初始化容量小于 0 ，抛出异常
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    // 如果容量大于 1 << 30 = 1073741824，则设置为 1 << 30，也即 map 最大的容量为 2^30
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    // 校验 loadFactor
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    // 设置 loadFactor
    this.loadFactor = loadFactor;
    // 计算 threshold，也即数组可容纳的最大容量，达到此值后再次存储需要进行扩容
    this.threshold = tableSizeFor(initialCapacity);
}

public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}

public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}

public HashMap(Map<? extends K, ? extends V> m) {
    // 默认为 0.75
    this.loadFactor = DEFAULT_LOAD_FACTOR;
    putMapEntries(m, false);
}
----

负载因子衡量的是一个散列表的空间的使用程度,负载因子越大表示散列表的装填程度越高,反之愈小.对于使用链表法的散列表来说,查找一个元素的平均时间是 `O(1+a)`,因此
如果负载因子越大,对空间的利用更充分,然而后果是查找效率的降低;如果负载因子太小, 那么散列表的数据将过于稀疏,对空间造成严重浪费.

HashMap 的实现中,通过 `threshold` 字段来判断 `HashMap` 的可存储的最大容量:

结合负载因子的定义公式可知,`threshold` 就是在此 `loadFactor` 和 `capacity` 对应下允许的最大元素数目,超过这个数目就重新 `resize`. 默认的的负载因子 0.75 是对空间和时间效率的一个平衡选择.当容量超出此最大容量时, resize 后的 HashMap 容量是容量的两倍

[NOTE]
====
注意：在默认无参构造方法中，并没有设置 HashMap 进行容量，只设置其负载因子大小。这其实是 HashMap 的一种懒加载机制，和 ArrayList 的无参构造方法一样，将容量的设置放置在了存储元素的操作里。
====

[[java-hashmap8-put-get]]
== HashMap 的存取实现

[[java-hashmap8-put]]
=== 存储

我们从 HashMap 的源码来分析 `HashMap` 的存储.

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
public V put(K key, V value) {
    // 计算 key 的 hash 值。
    return putVal(hash(key), key, value, false, true);
}

static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        // 调整数组大小，当数组为空时，初始化数组，n 即为数组长度.当我们使用无参构造方法创建 HashMap 时，在存储时会进入这里。初始化数组容量
        n = (tab = resize()).length;
    // 通过计算得到数组下标。并将当前位置元素保存在 p 中，如果 p 为空
    if ((p = tab[i = (n - 1) & hash]) == null)
        // 如果此位置不存在元素，则保存在此位置
        tab[i] = newNode(hash, key, value, null);
    else {
        Node<K,V> e; K k;
        // 如果存在值，判断 p 的 hash 值 key 是否和当前元素相等，或者 key.equals(k)
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            // 将节点 p 赋值给 e
            e = p;
        // 如果 p 红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            // binCount 用来计数链表中节点的个数
            for (int binCount = 0; ; ++binCount) {
                // 当前节点的下一个节点是否为 null，当为空时，将元素保存到 p 的下一个节点
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // 因为 binCount 是从 0 开始的，所以当节点数大于 8 时。
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        // 将链表转为红黑树，注意，此时还不会转换，因为转换为红黑树必须满足两个条件，
                        // 这里的链表节点数大于 8 只是其中一个条件,另外一个条件是数组长度必须大于 64.
                        // 可在 treeifyBin 方法中查看
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                // 将指针置于当前节点
                p = e;
            }
        }
        // 当 key 存在时，是否覆盖，默认覆盖。
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            // 此处为 LinkedHashMap 服务，在 LinkedHashMap 中讲解
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 判断数组容量是否达到 数组容量的 0.75
    if (++size > threshold)
        // 当存储元素到达数组容量的 0.75，进行容量调整
        resize();
    // 此处为 LinkedHashMap 服务，在 LinkedHashMap 中讲解
    afterNodeInsertion(evict);
    return null;
}
----

从上面的源代码中可以看出: 当我们往 `HashMap` 中 `put` 元素的时候,先根据 `key` 的 `hashCode` 重新计算 `hash` 值,根据 `hash` 值得到这个元素在数组中的位置(即下标).

如果数组该位置上已经存放有其他元素了,那么在这个位置上的元素将以链表的形式存放,新加入的放在链尾, 如果数组该位置上没有元素,就直接将该元素放到此数组中的该位置上.

当系统决定存储 `HashMap` 中的 key-value 对时,完全没有考虑 `Node` 中的 `value`,仅仅只是根据 `key` 来计算并决定每个 `Node` 的存储位置.我们完全可以把 `Map` 集合中的 `value` 当成 `key` 的附属,当系统决定了 `key` 的存储位置之后,`value` 随之保存在那里即可.

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
----

`hash(int h)` 方法根据 `key` 的 `hashCode` 重新计算一次散列.此算法加入了高位计算,防止低位不变,高位变化时,造成的 `hash` 冲突.

我们可以看到在 `HashMap` 中要找到某个元素,需要根据 `key` 的 `hash` 值来求得对应数组中的位置.如何计算这个位置就是 hash 算法.前面说过 `HashMap` 的数据结构是数组和链表的结合,所以我们当然希望这个 `HashMap` 里面的 元素位置尽量的分布均匀些,尽量 使得每个位置上的元素数量只有一个,那么当我们用 hash 算法求得这个位置的时候,马上就可以知道对应位置的元素就是我们要的,而不用再去遍历链表,这样就大大优化了查询的效率.

对于任意给定的对象,只要它的 `hashCode()` 返回值相同,那么程序调用 `hash(Object h)` 方法所计算得到的 `hash` 码值总是相同的.我们首先想到的就是把 `hash` 值对数组长度取模运算,这样一来,元素的分布相对来说是比较均匀的.但是, "模" 运算的消耗还是比较大的,
在 `HashMap` 中是这样做的: 调用 `(n - 1) & hash` 方法来计算该对象应该保存在 `table` 数组的哪个索引处. `n` 为数组长度，代码如下:

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
// 截取自 putVal 方法
if ((p = tab[i = (n - 1) & hash]) == null)
    tab[i] = newNode(hash, key, value, null);
----

这个方法非常巧妙,它通过 `h & (table.length -1)` 来得到该对象的保存位,而 `HashMap` 底层数组的长度总是 2 的 n 次方,这是 `HashMap` 在速度上的优化:

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
final Node<K,V>[] resize() {
    // 省略部分代码...
    // 截取自 resize 方法，对数组容量进行调整
    // newCap 为新数组大小，newThr 为新的负载因子，初始化为 0
    int newCap, newThr = 0;
    // oldCap 旧数组大小，oldThr 为旧的负载因子
    if (oldCap > 0) {
        // MAXIMUM_CAPACITY = 1 << 30
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 新的数组大小调整为就数组的 2 倍。新的负载因子也为原来的 2 倍。
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        // 初始化。
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    // 省略部分代码...
    return newTab;
}
----

这段代码保证初始化时 `HashMap` 的容量总是 2 的 n 次方,即底层数组的长度总是为 2 的 n 次方.当 length 总是 2 的 n 次方时,`h & (table.length -1)` 运算等价于对 `table.length - 1` 取模,也就是
`h % (table.length -1)`,但是 `&` 比 `%` 具有更高的效率. 这看上去很简单,其实比较有玄机的,我们举个例子来说明:
假设数组长度分别为 15 和 16,优化后的 hash 码分别为 8 和 9,那么 `&` 运算后的结果如下:

image::{oss-images}/collection/java-hashmap2.png[]

从上面的例子中可以看出: 当它们和 15-1(1110) "与" 的时候,产生了相同的结果, 也就是说它们会定位到数组中的同一个位置上去,这就产生了碰撞,8 和9 会被放到数组中 的同一个位置上形成链表,那么查询的时候就需要遍历这个链 表,得到 8 或者 9,这样就 降低了查询的效率.同时,我们也可以发现,当数组长度为 15 的时候,hash 值会与 15-1 (1110) 进行 "与" ,那么 最后一位永远是 0,而 `0001,0011,0101,1001,1011,0111,
1101` 这几个位置永远都不能存放元素了,空间浪费相当大,更糟的是这种情况中,数组可以使用的位置比数组长度小了很多,这意味着进一步增加了碰撞的几率,减慢了查询的效率！
而当数组长度为 16 时,即为 2 的 n 次方时,`2n-1` 得到的二进制数的每个位上的值都为 `1`, 这使得在低位上 `&` 时,得到的和原 `hash` 的低位相同,加之 `hash(Object key)` 方法对 `key` 的 `hashCode`
的进一步优化,加入了高位计算,就使得只有相同的 hash 值的两个值才会被放到数组中的同一个位置上形成链表.所以说,当数组长度为 2 的 n 次幂的时候,不同的 `key` 算得 `index` 相同的几率较小,那么数据在数组上分布就比较均匀,也就是说碰撞的几率小,相对的,查询的时候就不用遍历某个位置上的链表,这样查询效率也就较高了.


根据上面 `put` 方法的源代码可以看出,当程序试图将一个 key-value 对放入 HashMap 中时,程序首先根据该 `key` 的 `hashCode()` 返回值决定该 `Node` 的存储位置: 如果两个 `Node` 的 `key` 的 `hashCode()` 返回值相同,那它们的存储位置相同.如果这两个 `Node` 的 key 通过 equals 比较返回 true,新添加 `Node` 的 `value` 将覆盖集合中原有 `Node` 的 `value`,但 `key` 不会覆盖.如果这两个 `Node` 的 `key` 通过 `equals` 比较返回 false, 新添加的 NODE 将与集合中原有 `Node` 形成 `Node` 链,而且新添加的 `Node` 位于 `Node` 链的尾部.

[[java-hashmap8-get]]
=== 读取

Java 代码:

[source,java,indent=0,subs="verbatim,quotes",role="primary"]
.Java
----
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(key)) == null ? null : e.value;
}

final Node<K,V> getNode(Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n, hash; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & (hash = hash(key))]) != null) {
        // 检查第一个节点，主要还是为了判断后续节点是红黑树还是链表。必须先确保第一个节点存在
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            // 循环遍历链表
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
----

有了上面存储时的 hash 算法作为基础,理解起来这段代码就很容易了.从上面的源代码中可以看出: 从 HashMap 中 `get` 元素时,首先计算 key 的 `hashCode`,找到数组中对应
位置的某一元素,然后通过 key 的 `equals` 方法在对应位置的链表中找到需要的元素.

归纳起来简单地说,HashMap 在底层将 key-value 当成一个整体进行处理,这个整体就是一个 Node 对象.HashMap 底层采用一个 `Node<K,V>[]` 数组来保存所有的 key-value 对,当
需要存储一个 `Node` 对象时,会根据 hash 算法来决定其在数组中的存储位置,在根据 equals 方法决定其在该数组位置上的链表中的存储位置;当需要取出一个 `Node` 时,也会根据 hash
算法找到其在数组中的存储位置,再根据 `equals` 方法从该位置上的链表中取出该 `Node`

[[java-hashmap8-put-resize]]
== HashMap 的 resize

当 HashMap 中的元素越来越多的时候,hash 冲突的几率也就越来越高,因为数组的长度是固定的.所以为了提高查询的效率,就要对 HashMap 的数组进行扩容,数组扩容这个操作也会出现在 ArrayList 中,这是一个常用的操作,而在 HashMap 数组扩容之后,最消耗性能的点就出现了: 原数组中的数据必须重新计算其在新数组中的位置,并放进去,这就是 resize.

那么 HashMap 什么时候进行扩容呢? 当 HashMap 中的元素个数超过 `数组大小*loadFactor` 时,就会进行数组扩容,loadFactor 的默认值为 `0.75`,这是一个折中的取值.也就是说,默认情况下,数组大小为 16,那么当 `HashMap` 中元素个数超过 `16*0.75=12` 的时候,就把数组的大小扩展为 2*16=32,即扩大一倍,然后重新计算每个元素在数组中的位置,而这是一个非常消耗性能的操作,所以如果我们已经预知 HashMap 中元素的个数,那么预设元素的个数能够有效的提高 HashMap 的性能.

[[java-hashmap8-fail]]
== Fail-Fast 机制

我们知道 `java.util.HashMap` 不是线程安全的,因此如果在使用迭代器的过程中有其他线程修改了 map,那么将抛出 `ConcurrentModificationException`,这就是所谓 fail-fast 策略.

这一策略在源码中的实现是通过 `modCount` 域,`modCount` 顾名思义就是修改次数,对 HashMap 内容的修改都将增加这个值,那么在迭代器初始化过程中会将这个值赋给迭代器的 `expectedModCount`.

在迭代过程中,判断 `modCount` 跟 `expectedModCount` 是否相等,如果不相等就表示已经有其他线程修改了 Map: 注意到 `modCount` 声明为 `volatile`,保证线程之间修改的可见性.

在 HashMap 的API 中指出: 由所有 HashMap 类的 "collection 视图方法" 所返回的迭代器都是快速失败的: 在迭代器创建之后,如果从结构上对映射进行修改,除非通过迭代器本身的 remove 方法,其他任何时间任何方式的修改,迭代器都将抛出 `ConcurrentModificationException`.因此,面对并发的修改,迭代器很快就会完全失败,而不冒在将来不确定的时间发生任意不确定行为的风险.

[NOTE]
====
迭代器的快速失败行为不能得到保证,一般来说,存在非同步的并发修改时,不可能作出任何坚决的保证.快速失败迭代器尽最大努力抛出 `ConcurrentModificationException`.因此,编写依赖于此异常的程序的做法是错误的,正确做法是: 迭代器的快速失败行为应该仅用于检测程序错误.
====

[[java-hashmap8-qa]]
== Q&A

*  例子一

&nbsp;&nbsp; Q:当两个对象的 hashcode 相同会发生什么?

&nbsp;&nbsp; A:因为 `hashcode` 相同,所以它们在数组中位置相同,‘碰撞’会发生.因为 `HashMap` 使用链表存储对象,这个 `Node` (包含有键值对的 Map.Entry 对象)会存储在链表中.

*  例子二

&nbsp;&nbsp; Q:如果两个键的 `hashcode` 相同,你如何获取值对象?

&nbsp;&nbsp; A:当我们调用 `get()` 方法,HashMap 会使用键对象的 `hashcode` 找到在数组中位置, 找到位置之后,会调用 `keys.equals()` 方法去找到链表中正确的节点,最终找到要找的值对象.

*  例子三

&nbsp;&nbsp; Q:重新调整 `HashMap` 大小存在什么问题吗?

&nbsp;&nbsp; A:可能产生条件竞争(race condition).因为如果两个线程都发现 `HashMap` 需要重新调整大小了,它们会同时试着调整大小.在调整大小的过程中,存储在链表中的元素的次序会反过来,因为移动到新的数组中的位置的时候,`HashMap` 并不会将元素放在链表的尾部,而是放在头部,这是为了避免尾部遍历(tail traversing).如果条件竞争发生了,那么就死循环了.

*  例子四

&nbsp;&nbsp; Q:为什么 String, Integer 这样的 wrapper 类适合作为键?

&nbsp;&nbsp; A:因为 String 是不可变的,也是 `final` 的,而且已经重写了 `equals()` 和 `hashCode()` 方法了.其他的 wrapper 类也有这个特点.不可变性是必要的,因为为了要计算 `hashCode()`,就要防止键值改变,如果键值在放入时和获取时返回不同的 `hashcode` 的话,那么就不能从 `HashMap` 中找到你想要的对象.不可变性还有其他的优点如线程安全.

[[java-hashmap8-kuozhan]]
== 扩展
*  ConcurrentHashMap.



